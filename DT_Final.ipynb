{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "#Step 1 - function call required\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from math import log\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "# Implement your decision tree below\n",
    "# Used the ID3 algorithm to implement the Decision Tree\n",
    "\n",
    "# Class used for learning and building the Decision Tree using the given Training Set\n",
    "class DecisionTree():\n",
    "    tree = {}\n",
    "\n",
    "    def learn(self, training_set, attributes, target):\n",
    "        self.tree = build_tree(training_set, attributes, target)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files( filepath):\n",
    "    '''\n",
    "    input - File path of input file. \n",
    "    read file and convert into 2d array.\n",
    "    handles only csv format.\n",
    "    returns Column header and dataset into two different variable.\n",
    "\n",
    "    '''\n",
    "    datastore=[]\n",
    "    final_dataset ={}\n",
    "    with open(filepath,'r') as files:\n",
    "        for line in files.readlines():\n",
    "            lines=line.strip().split(',')\n",
    "            for i in range(len(lines)):\n",
    "                if len(lines[i])==0 or len(lines[i])== None:\n",
    "                    lines[i]=None\n",
    "                elif lines[i][0]=='\"' or lines[i][-1]=='\"':\n",
    "                    lines[i]=lines[i][1:-1]\n",
    "                    value=digit_check(lines[i])\n",
    "                else:\n",
    "                    value=digit_check(lines[i])\n",
    "                if value=='int':\n",
    "                    lines[i]=int(lines[i])\n",
    "                elif value=='float':\n",
    "                    lines[i]=float(lines[i])\n",
    "                else:\n",
    "                    lines[i]=lines[i]\n",
    "            datastore.append(lines)\n",
    "\n",
    "    columns=datastore[0]\n",
    "    dataset=datastore[1:]\n",
    "\n",
    "\n",
    "    return columns,dataset\n",
    "\n",
    "\n",
    "#Step 1.1\n",
    "def digit_check(user_input):\n",
    "    '''\n",
    "    convert string digits into integer / float.\n",
    "    inputs each element of 2d array.\n",
    "    return int/float/string to read_files function.\n",
    "    required - 2d array reads all elements as string char.\n",
    "    '''\n",
    "    try:\n",
    "       val = int(user_input)\n",
    "       return 'int'\n",
    "    except ValueError:\n",
    "      try:\n",
    "        val = float(user_input)\n",
    "        return 'float'\n",
    "      except ValueError:\n",
    "          return 'string'\n",
    "\n",
    "\n",
    "\n",
    "#Step 3.1\n",
    "\n",
    "def random_number(low, high):\n",
    "    \"\"\"\n",
    "    a time based random number generator \n",
    "    uses the random time between a user's input events\n",
    "    returns an integer between low and high-1\n",
    "    \"\"\"\n",
    "    return int(low + int(time.time()*1000) % (high - low))\n",
    "\n",
    "\n",
    "\n",
    "#Step 3.2\n",
    "def random_indices(high,test_size):\n",
    "    '''\n",
    "    generates random sample index.\n",
    "    inputs length of dataset and sample size\n",
    "    returns radom indices\n",
    "\n",
    "    '''\n",
    "    test_indices=[]\n",
    "    while len(test_indices)<test_size:\n",
    "        indices=random_number(len(test_indices),high)\n",
    "        test_indices.append(indices)\n",
    "        test_indices = list( dict.fromkeys(test_indices) )\n",
    "    test_indices.sort()\n",
    "    return test_indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 3 - function call required\n",
    "def test_train_split(df,test_size):\n",
    "    '''\n",
    "    input dataset and test size\n",
    "    returns test and training data set\n",
    "\n",
    "    '''\n",
    "    high=len(df)\n",
    "    train_df=[]\n",
    "    if isinstance(test_size,float):\n",
    "        test_size=round(test_size*len(df))\n",
    "    test_indices = random_indices(high,test_size)\n",
    "    test_df=[df[value] for value in test_indices]\n",
    "    for i in range(len(df)):\n",
    "        if i not in test_indices:\n",
    "            train_df.append(df[i])\n",
    "    return test_df,train_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Majority Function which tells which class has more entries in given data-set\n",
    "def default_Y(attributes, data, target):\n",
    "\n",
    "    freq = {}\n",
    "    index = attributes.index(target)\n",
    "\n",
    "    for tuple in data:\n",
    "        if (tuple[index] in freq.keys()):\n",
    "            freq[tuple[index]] += 1 \n",
    "        else:\n",
    "            freq[tuple[index]] = 1\n",
    "\n",
    "    max = 0\n",
    "    major = \"\"\n",
    "\n",
    "    for key in freq.keys():\n",
    "        if freq[key]>max:\n",
    "            max = freq[key]\n",
    "            major = key\n",
    "\n",
    "    return major\n",
    "\n",
    "\n",
    "# This function will get unique values for that particular attribute from the given data\n",
    "def get_values(data, attributes, attr):\n",
    "\n",
    "    index = attributes.index(attr)\n",
    "    values = []\n",
    "\n",
    "    for entry in data:\n",
    "        if entry[index] not in values:\n",
    "            values.append(entry[index])\n",
    "\n",
    "    return values\n",
    "\n",
    "# This function will get all the rows of the data where the chosen \"best\" attribute has a value \"val\"\n",
    "def get_data(data, attributes, best, val):\n",
    "\n",
    "    new_data = [[]]\n",
    "    index = attributes.index(best)\n",
    "\n",
    "    for entry in data:\n",
    "        if (entry[index] == val):\n",
    "            newEntry = []\n",
    "            for i in range(0,len(entry)):\n",
    "                if(i != index):\n",
    "                    newEntry.append(entry[i])\n",
    "            new_data.append(newEntry)\n",
    "\n",
    "    new_data.remove([])    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "# This function is used to build the decision tree using the given data, attributes and the target attributes. \n",
    "# It returns the decision tree in the end.\n",
    "def build_tree(data, attributes, target):\n",
    "\n",
    "    data = data[:]\n",
    "    #print(data)\n",
    "    vals = [record[attributes.index(target)] for record in data]\n",
    "    print(\"vals: \", vals)\n",
    "    default = default_Y(attributes, data, target)\n",
    "    print(\"default after calling default_Y: \", default)  \n",
    "    if not data or (len(attributes) - 1) <= 0:\n",
    "        return default\n",
    "    elif vals.count(vals[0]) == len(vals):\n",
    "        return vals[0]\n",
    "    else:\n",
    "        #best = attr_choose(data, attributes, target)\n",
    "        best = attr_choose_new(data, attributes, target)\n",
    "        print(\"best column to split\",best)\n",
    "        tree = {best:{}}\n",
    "    \n",
    "        for val in get_values(data, attributes, best):\n",
    "            new_data = get_data(data, attributes, best, val)\n",
    "            newAttr = attributes[:]\n",
    "            newAttr.remove(best)\n",
    "            subtree = build_tree(new_data, newAttr, target)\n",
    "            tree[best][val] = subtree\n",
    "    \n",
    "    return tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(pi):\n",
    "    '''\n",
    "    return the Entropy of a probability distribution:\n",
    "    entropy(p) = − SUM (Pi * log(Pi) )\n",
    "    defintion:\n",
    "            entropy is a metric to measure the uncertainty of a probability distribution.\n",
    "    entropy ranges between 0 to 1\n",
    "    Low entropy means the distribution varies (peaks and valleys).\n",
    "    High entropy means the distribution is uniform.\n",
    "\n",
    "    '''\n",
    "\n",
    "    total = 0\n",
    "    for p in pi:\n",
    "        p = p / sum(pi)\n",
    "        if p != 0:\n",
    "            total += p * log(p, 2)\n",
    "        else:\n",
    "            total += 0\n",
    "    total *= -1\n",
    "    return total\n",
    "\n",
    "\n",
    "def gain(Y_count_list, feature_list):\n",
    "    '''\n",
    "    return the information gain:\n",
    "    gain(D, A) = entropy(D)−􏰋 SUM ( |Di| / |D| * entropy(Di) )\n",
    "    '''\n",
    "\n",
    "    total = 0\n",
    "    for v in feature_list:\n",
    "        total += sum(v) / sum(Y_count_list) * entropy(v)\n",
    "\n",
    "    gain = entropy(Y_count_list) - total\n",
    "    return gain\n",
    "\n",
    "def convert_feature_to_x_y_relation( feature):\n",
    "    '''\n",
    "    given a feature, this will give all [x,y] in groups\n",
    "    '''\n",
    "    feature_tuple = (tuple(f) for f in feature)\n",
    "    #print(feature_tuple)\n",
    "\n",
    "\n",
    "    ls = []\n",
    "    c= Counter(feature_tuple)\n",
    "    #print(\"Counter: \",c)\n",
    "    for l in c:\n",
    "        ls.append([l[0] , l[1], c[l]])\n",
    "    #print(\"ls\",ls)\n",
    "\n",
    "    key_func = lambda x: x[0].strip()\n",
    "    ls.sort()\n",
    "    gr = []  \n",
    "\n",
    "    for key, group in itertools.groupby(ls, key_func):\n",
    "       #print(\"key_func\",key, list(group))\n",
    "       gr.append(list(group))\n",
    "     #print(\"gr\", gr)\n",
    "\n",
    "    gr.sort()\n",
    "    final_list = []\n",
    "    for i,grs in enumerate(gr):\n",
    "        if len(grs) == 2 :\n",
    "            final_list.append([gr[i][0][2],gr[i][1][2]])\n",
    "        elif gr[i][0][1] == 0:\n",
    "            final_list.append([gr[i][0][2],0])\n",
    "        elif gr[i][0][1] == 1:\n",
    "            final_list.append([0,gr[i][0][2]])        \n",
    "    return final_list\n",
    "\n",
    "#############################################Variable dist is a dictionary with Key as feature and value as a list giving feature value and dependent variable#######################################################\n",
    "def get_dictionary_with_x_groups(columname,X,Y):\n",
    "    Variable_dict ={}\n",
    "    for colm in  range(len(columname)-1):\n",
    "        temp=[]\n",
    "        for x,y in zip([x[colm] for x in X] ,Y):\n",
    "            temp.append([x,y])\n",
    "        Variable_dict[columname[colm]] = temp  \n",
    "        temp.append([x,y])\n",
    "    return Variable_dict\n",
    "\n",
    "def give_x_information_gain(Variable_dict, Y_count_list, attributes):\n",
    "    root={}\n",
    "    groups={}\n",
    "    for key in Variable_dict.keys():\n",
    "        #print(\"Groups for Feature %s is %s\" %(key,  dt.convert_feature_to_x_y_relation(Variable_dict[key])))\n",
    "        #print(\"Information Gain for Feature %s is %s\" %(key,  dt.gain(Y_count_list,dt.convert_feature_to_x_y_relation(Variable_dict[key]))))\n",
    "        root[key] =  gain(Y_count_list,convert_feature_to_x_y_relation(Variable_dict[key]))\n",
    "        groups[key] = Variable_dict[key]\n",
    "    Max_IG = max(root, key=root.get) \n",
    "    root_index = attributes.index(Max_IG)\n",
    "    Max_IG_Value = root[Max_IG]\n",
    "    return Max_IG,root_index,Max_IG_Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_choose_new(data, attributes, target):\n",
    "    Variable_dict ={}\n",
    "    #Below gives dataset as dictionary of all columns as key and value as a list of [value of x, value of Y]\n",
    "    X = [x[:-1] for x in data]\n",
    "    Y = [x[-1] for x in data]\n",
    "    print(\"X\",X)\n",
    "    print(\"Y\",Y)\n",
    "    Y_count_list = [Y.count(y) for y in set(Y)]\n",
    "    Variable_dict = get_dictionary_with_x_groups(attributes,X,Y)\n",
    "    print(\"All rows as value and key as column\", Variable_dict)\n",
    "    print(\"\\n\")\n",
    "    Max_IG,root_index,Max_IG_Value = give_x_information_gain(Variable_dict , Y_count_list, attributes)\n",
    "    return attributes[root_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vals:  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "default after calling default_Y:  1\n",
      "X [['Rainy', 'Hot', 'High', 'False'], ['Rainy', 'Mild', 'High', 'False'], ['Rainy', 'Cool', 'Normal', 'False'], ['Rainy', 'Mild', 'Normal', 'True'], ['Overcast', 'Cool', 'Normal', 'True'], ['Overcast', 'Mild', 'High', 'True'], ['Overcast', 'Hot', 'Normal', 'False'], ['Sunny', 'Mild', 'Normal', 'False'], ['Sunny', 'Mild', 'High', 'False'], ['Sunny', 'Cool', 'Normal', 'False'], ['Sunny', 'Cool', 'Normal', 'True'], ['Sunny', 'Mild', 'High', 'True'], ['Sunny', 'Mild', 'High', 'True']]\n",
      "Y [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "All rows as value and key as column {'Outlook': [['Rainy', 0], ['Rainy', 0], ['Rainy', 1], ['Rainy', 1], ['Overcast', 1], ['Overcast', 1], ['Overcast', 1], ['Sunny', 1], ['Sunny', 1], ['Sunny', 1], ['Sunny', 0], ['Sunny', 0], ['Sunny', 1], ['Sunny', 1]], 'Temp': [['Hot', 0], ['Mild', 0], ['Cool', 1], ['Mild', 1], ['Cool', 1], ['Mild', 1], ['Hot', 1], ['Mild', 1], ['Mild', 1], ['Cool', 1], ['Cool', 0], ['Mild', 0], ['Mild', 1], ['Mild', 1]], 'Humidity': [['High', 0], ['High', 0], ['Normal', 1], ['Normal', 1], ['Normal', 1], ['High', 1], ['Normal', 1], ['Normal', 1], ['High', 1], ['Normal', 1], ['Normal', 0], ['High', 0], ['High', 1], ['High', 1]], 'Windy': [['False', 0], ['False', 0], ['False', 1], ['True', 1], ['True', 1], ['True', 1], ['False', 1], ['False', 1], ['False', 1], ['False', 1], ['True', 0], ['True', 0], ['True', 1], ['True', 1]]}\n",
      "\n",
      "\n",
      "best column to split Outlook\n",
      "vals:  [0, 0, 1, 1]\n",
      "default after calling default_Y:  0\n",
      "X [['Hot', 'High', 'False'], ['Mild', 'High', 'False'], ['Cool', 'Normal', 'False'], ['Mild', 'Normal', 'True']]\n",
      "Y [0, 0, 1, 1]\n",
      "All rows as value and key as column {'Temp': [['Hot', 0], ['Mild', 0], ['Cool', 1], ['Mild', 1], ['Mild', 1]], 'Humidity': [['High', 0], ['High', 0], ['Normal', 1], ['Normal', 1], ['Normal', 1]], 'Windy': [['False', 0], ['False', 0], ['False', 1], ['True', 1], ['True', 1]]}\n",
      "\n",
      "\n",
      "best column to split Humidity\n",
      "vals:  [0, 0]\n",
      "default after calling default_Y:  0\n",
      "vals:  [1, 1]\n",
      "default after calling default_Y:  1\n",
      "vals:  [1, 1, 1]\n",
      "default after calling default_Y:  1\n",
      "vals:  [1, 1, 1, 0, 0, 1]\n",
      "default after calling default_Y:  1\n",
      "X [['Mild', 'Normal', 'False'], ['Mild', 'High', 'False'], ['Cool', 'Normal', 'False'], ['Cool', 'Normal', 'True'], ['Mild', 'High', 'True'], ['Mild', 'High', 'True']]\n",
      "Y [1, 1, 1, 0, 0, 1]\n",
      "All rows as value and key as column {'Temp': [['Mild', 1], ['Mild', 1], ['Cool', 1], ['Cool', 0], ['Mild', 0], ['Mild', 1], ['Mild', 1]], 'Humidity': [['Normal', 1], ['High', 1], ['Normal', 1], ['Normal', 0], ['High', 0], ['High', 1], ['High', 1]], 'Windy': [['False', 1], ['False', 1], ['False', 1], ['True', 0], ['True', 0], ['True', 1], ['True', 1]]}\n",
      "\n",
      "\n",
      "best column to split Windy\n",
      "vals:  [1, 1, 1]\n",
      "default after calling default_Y:  1\n",
      "vals:  [0, 0, 1]\n",
      "default after calling default_Y:  0\n",
      "X [['Cool', 'Normal'], ['Mild', 'High'], ['Mild', 'High']]\n",
      "Y [0, 0, 1]\n",
      "All rows as value and key as column {'Temp': [['Cool', 0], ['Mild', 0], ['Mild', 1], ['Mild', 1]], 'Humidity': [['Normal', 0], ['High', 0], ['High', 1], ['High', 1]]}\n",
      "\n",
      "\n",
      "best column to split Temp\n",
      "vals:  [0]\n",
      "default after calling default_Y:  0\n",
      "vals:  [0, 1]\n",
      "default after calling default_Y:  0\n",
      "X [['High'], ['High']]\n",
      "Y [0, 1]\n",
      "All rows as value and key as column {'Humidity': [['High', 0], ['High', 1], ['High', 1]]}\n",
      "\n",
      "\n",
      "best column to split Humidity\n",
      "vals:  [0, 1]\n",
      "default after calling default_Y:  0\n",
      "[['Rainy', 'Hot', 'High', 'False', 0],\n",
      " ['Rainy', 'Mild', 'High', 'False', 0],\n",
      " ['Rainy', 'Cool', 'Normal', 'False', 1],\n",
      " ['Rainy', 'Mild', 'Normal', 'True', 1],\n",
      " ['Overcast', 'Cool', 'Normal', 'True', 1],\n",
      " ['Overcast', 'Mild', 'High', 'True', 1],\n",
      " ['Overcast', 'Hot', 'Normal', 'False', 1],\n",
      " ['Sunny', 'Mild', 'Normal', 'False', 1],\n",
      " ['Sunny', 'Mild', 'High', 'False', 1],\n",
      " ['Sunny', 'Cool', 'Normal', 'False', 1],\n",
      " ['Sunny', 'Cool', 'Normal', 'True', 0],\n",
      " ['Sunny', 'Mild', 'High', 'True', 0],\n",
      " ['Sunny', 'Mild', 'High', 'True', 1]]\n",
      "{'Outlook': {'Overcast': 1,\n",
      "             'Rainy': {'Humidity': {'High': 0, 'Normal': 1}},\n",
      "             'Sunny': {'Windy': {'False': 1,\n",
      "                                 'True': {'Temp': {'Cool': 0,\n",
      "                                                   'Mild': {'Humidity': {'High': 0}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "data = []\n",
    "path =os.path.abspath(os.getcwd())\n",
    "# load and prepare data\n",
    "\n",
    "#filename = os.path.join(path,\"data/data_banknote_authentication.csv\")\n",
    "path =os.path.abspath(os.getcwd())\n",
    "# load and prepare data\n",
    "\n",
    "#filename = os.path.join(path,\"data/data_banknote_authentication.csv\")\n",
    "filename = os.path.join(path,\"data/Golf_data_set.csv\")\n",
    "attributes,dataset=read_files(filename)\n",
    "\n",
    "target = attributes[-1]\n",
    "\n",
    "#####Breaking down the dataset into train_df and test_df, and giving 10% as the split\n",
    "test_set,training_set=test_train_split(dataset,0.1)\n",
    "\n",
    "tree = DecisionTree()\n",
    "tree.learn( training_set, attributes, target )\n",
    "pprint.pprint(training_set)\n",
    "pprint.pprint(tree.tree)\n",
    "\n",
    "#best = attr_choose_new(training_set, attributes, target)\n",
    "#print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
